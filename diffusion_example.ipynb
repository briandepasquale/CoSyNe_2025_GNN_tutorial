{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brain/miniforge3/envs/gnn_tutorial/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# code to install all dependencies in a mamba environemnt\n",
    "# !pip3 install torch\n",
    "# !mamba install pyg -c pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import GDC\n",
    "\n",
    "gdc = GDC(\n",
    "    self_loop_weight=1,\n",
    "    normalization_in=\"sym\",\n",
    "    normalization_out=\"col\",\n",
    "    diffusion_kwargs=dict(method=\"ppr\", alpha=0.15, eps=1e-4),\n",
    "    sparsification_kwargs=dict(method=\"threshold\", eps=1e-4),\n",
    "    exact=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 2) Load dataset and apply GDC\n",
    "# ----------------------------------------------------------------------\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=gdc)\n",
    "dataset = Planetoid(root=\"data/Planetoid\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "# Now data.edge_index and data.edge_attr (if any) represent the diffused graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import spmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Apply GDC to get a diffused adjacency:\n",
    "data_diffused = gdc(data)  # This modifies edge_index, edge_attr in a new Data object.\n",
    "\n",
    "# data_diffused.edge_index is the \"diffused\" adjacency structure\n",
    "# data_diffused.edge_attr (if not None) are the corresponding weights\n",
    "\n",
    "# 2) Multiply the new adjacency by your features:\n",
    "edge_index = data_diffused.edge_index\n",
    "edge_weight = data_diffused.edge_attr  # or None if unweighted\n",
    "X = data.x\n",
    "\n",
    "# spmm performs sparse matrix multiplication:  X_new = A * X\n",
    "# where A is encoded by (edge_index, edge_weight)\n",
    "X_diffused = spmm(edge_index, edge_weight, X.size(0), X.size(0), X)\n",
    "\n",
    "# Now X_diffused has the \"diffused\" features for each node\n",
    "data.x = X_diffused  # Overwrite original features if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 3) Define a simple GCN to use on the new diffused graph\n",
    "# ----------------------------------------------------------------------\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GCN(dataset.num_features, 64, dataset.num_classes).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 0.0677, Train Acc: 1.0000, Val Acc: 0.7880, Test Acc: 0.8050\n",
      "Epoch: 040, Loss: 0.0209, Train Acc: 1.0000, Val Acc: 0.7960, Test Acc: 0.7990\n",
      "Epoch: 060, Loss: 0.0269, Train Acc: 1.0000, Val Acc: 0.7960, Test Acc: 0.8120\n",
      "Epoch: 080, Loss: 0.0254, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8040\n",
      "Epoch: 100, Loss: 0.0229, Train Acc: 1.0000, Val Acc: 0.7840, Test Acc: 0.8110\n",
      "Epoch: 120, Loss: 0.0201, Train Acc: 1.0000, Val Acc: 0.7840, Test Acc: 0.8070\n",
      "Epoch: 140, Loss: 0.0173, Train Acc: 1.0000, Val Acc: 0.7780, Test Acc: 0.8070\n",
      "Epoch: 160, Loss: 0.0159, Train Acc: 1.0000, Val Acc: 0.7860, Test Acc: 0.8100\n",
      "Epoch: 180, Loss: 0.0183, Train Acc: 1.0000, Val Acc: 0.7840, Test Acc: 0.8160\n",
      "Epoch: 200, Loss: 0.0125, Train Acc: 1.0000, Val Acc: 0.7840, Test Acc: 0.8130\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 4) Training loop\n",
    "# ----------------------------------------------------------------------\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    preds = logits.argmax(dim=1)\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        acc = (preds[mask] == data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    if epoch % 20 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, \"\n",
    "            f\"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
